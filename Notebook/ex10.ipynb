{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Note that `ratings` is a sparse matrix that in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 1000, number of users: 10000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"data/data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nonzero elements in original data:1176873\n",
      "Total number of nonzero elements in train data:1058916\n",
      "Total number of nonzero elements in test data:117957\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_train_test_data\n",
    "from helpers import split_data\n",
    "\n",
    "valid_ratings, train_unfiltered, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from outliers_filtering import *\n",
    "#d = disagreements(train_unfiltered)\n",
    "#plot_disagreements(d)\n",
    "#train = filter_outliers(train_unfiltered,d)\n",
    "#nfiltered = train_unfiltered.nnz - train.nnz\n",
    "#print(\"number of filtered ratings : {}\".format(nfiltered))\n",
    "train = train_unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from outliers_filtering import threshold_tests\n",
    "threshold_tests(d, train_unfiltered, valid_ratings, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the global mean to do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11567752157\n",
      "1.11905221478\n"
     ]
    }
   ],
   "source": [
    "from helpers import calculate_mse\n",
    "from baselines import baseline_global_mean, compute_rmse\n",
    "\n",
    "train_mean, test_mean = baseline_global_mean(train, test)\n",
    "pred = np.ones(train.shape) * train_mean\n",
    "test_pred = np.ones(test.shape) * test_mean\n",
    "\n",
    "\n",
    "rmse_test = compute_rmse(test, test_pred)\n",
    "rmse_submission = compute_rmse(valid_ratings, pred)\n",
    "print(rmse_test)\n",
    "print(rmse_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the user means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from baselines import baseline_user_mean\n",
    "\n",
    "train_means, test_means = baseline_user_mean(train, test)\n",
    "train_means_list = train_means.tolist()\n",
    "pred = np.ones(train.shape)\n",
    "for col in range(train.shape[1]):\n",
    "    pred[:,col] *= train_means_list[0][col]\n",
    "test_means_list = test_means.tolist()\n",
    "test_pred = np.ones(test.shape)\n",
    "for col in range(test.shape[1]):\n",
    "    test_pred[:,col] *= test_means_list[0][col]\n",
    "\n",
    "rmse_test = compute_rmse(test, test_pred)\n",
    "rmse_submission = compute_rmse(valid_ratings, pred)\n",
    "print(rmse_test)\n",
    "print(rmse_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the item means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from baselines import baseline_item_mean\n",
    "from helpers import exportSubmission\n",
    "\n",
    "train_means, test_means = baseline_item_mean(train, test)\n",
    "train_means_list = train_means.tolist()\n",
    "pred = np.ones(train.shape)\n",
    "for col in range(train.shape[0]):\n",
    "    pred[col,:] *= train_means_list[col]\n",
    "test_means_list = test_means.tolist()\n",
    "test_pred = np.ones(test.shape)\n",
    "for col in range(test.shape[0]):\n",
    "    test_pred[col,:] *= test_means_list[col]\n",
    "\n",
    "rmse_test = compute_rmse(test, test_pred)\n",
    "rmse_submission = compute_rmse(valid_ratings, pred)\n",
    "print(rmse_test)\n",
    "print(rmse_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost by the method of matrix factorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: k = 30, RMSE on training set: 2.8472014949081195.\n",
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 1.7860476640497496.\n",
      "iter: 10, RMSE on training set: 1.072267813959614.\n",
      "iter: 20, RMSE on training set: 1.029250607266135.\n",
      "iter: 30, RMSE on training set: 1.010452695060202.\n",
      "iter: 40, RMSE on training set: 0.9985192477513356.\n",
      "iter: 50, RMSE on training set: 0.9898284969805184.\n",
      "iter: 60, RMSE on training set: 0.98306042559152.\n",
      "iter: 70, RMSE on training set: 0.977520361640855.\n",
      "iter: 80, RMSE on training set: 0.9727744711594994.\n",
      "iter: 90, RMSE on training set: 0.968712804164225.\n",
      "iter: 100, RMSE on training set: 0.965146057324347.\n",
      "iter: 110, RMSE on training set: 0.9617871970217926.\n",
      "iter: 120, RMSE on training set: 0.9588946017983973.\n",
      "iter: k = 30, RMSE on training set: 2.845651893735437.\n",
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 1.7890616400521184.\n",
      "iter: 10, RMSE on training set: 1.0768092672083396.\n",
      "iter: 20, RMSE on training set: 1.0323171685996395.\n",
      "iter: 30, RMSE on training set: 1.0124675971918653.\n",
      "iter: 40, RMSE on training set: 1.0001225313427475.\n",
      "iter: 50, RMSE on training set: 0.9911720384503273.\n",
      "iter: 60, RMSE on training set: 0.9842015224928877.\n",
      "iter: 70, RMSE on training set: 0.9783877930082385.\n",
      "iter: 80, RMSE on training set: 0.9735887103848948.\n",
      "iter: 90, RMSE on training set: 0.9692787670417963.\n",
      "iter: 100, RMSE on training set: 0.9657634759641389.\n",
      "iter: k = 30, RMSE on training set: 2.844020121459129.\n",
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 1.785347230242929.\n",
      "iter: 10, RMSE on training set: 1.070296409704634.\n",
      "iter: 20, RMSE on training set: 1.028908945970391.\n",
      "iter: 30, RMSE on training set: 1.0104767620372976.\n",
      "iter: 40, RMSE on training set: 0.9987365626238351.\n",
      "iter: 50, RMSE on training set: 0.990151549045768.\n",
      "iter: 60, RMSE on training set: 0.9833758457771931.\n",
      "iter: 70, RMSE on training set: 0.9775446362364879.\n",
      "iter: 80, RMSE on training set: 0.9728713270872879.\n",
      "iter: 90, RMSE on training set: 0.9686752679272491.\n",
      "iter: 100, RMSE on training set: 0.9649634311297922.\n",
      "iter: k = 30, RMSE on training set: 2.8380971455073962.\n",
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 1.7673684823991653.\n",
      "iter: 10, RMSE on training set: 1.0646506587728053.\n",
      "iter: 20, RMSE on training set: 1.0255065943841626.\n",
      "iter: 30, RMSE on training set: 1.0080824048402637.\n",
      "iter: 40, RMSE on training set: 0.9969714056242275.\n",
      "iter: 50, RMSE on training set: 0.9888756519764068.\n",
      "iter: 60, RMSE on training set: 0.9823437933132908.\n",
      "iter: 70, RMSE on training set: 0.9770093830537377.\n",
      "iter: 80, RMSE on training set: 0.9724985199915979.\n",
      "iter: 90, RMSE on training set: 0.9684464638883674.\n",
      "iter: 100, RMSE on training set: 0.9648565111764396.\n",
      "iter: 110, RMSE on training set: 0.9615269133171683.\n",
      "iter: 120, RMSE on training set: 0.9584377663278413.\n",
      "iter: k = 30, RMSE on training set: 2.8454623662870775.\n",
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 1.7901072537965308.\n",
      "iter: 10, RMSE on training set: 1.076251978446954.\n",
      "iter: 20, RMSE on training set: 1.033120228657138.\n",
      "iter: 30, RMSE on training set: 1.0131247708356164.\n",
      "iter: 40, RMSE on training set: 1.0008714125445113.\n",
      "iter: 50, RMSE on training set: 0.9917720827336796.\n",
      "iter: 60, RMSE on training set: 0.9843450284459607.\n",
      "iter: 70, RMSE on training set: 0.9786189295914288.\n",
      "iter: 80, RMSE on training set: 0.9738560541884114.\n",
      "iter: 90, RMSE on training set: 0.9693604294391007.\n",
      "iter: 100, RMSE on training set: 0.9654226382642626.\n",
      "iter: 110, RMSE on training set: 0.9621102935669487.\n",
      "iter: 120, RMSE on training set: 0.9590179224243155.\n",
      "iter: 130, RMSE on training set: 0.9561742830877902.\n",
      "[(array([[  8.59185029e-02,   1.47650817e-01,   8.01284744e-02, ...,\n",
      "          8.09320033e-02,   1.01185134e-01,   7.84178865e-02],\n",
      "       [  1.07328418e-01,   1.14748879e-01,   1.49500028e-01, ...,\n",
      "          1.06355911e-01,   8.78173027e-02,   9.03917317e-02],\n",
      "       [  9.69784011e-02,   1.09125171e-01,   1.16583836e-01, ...,\n",
      "          1.24260498e-01,   1.52797477e-01,   1.20116361e-01],\n",
      "       ..., \n",
      "       [  4.62279062e-02,   4.29968477e-02,   2.62502163e-02, ...,\n",
      "          7.44748130e-02,   6.65306762e-02,   2.46099445e-02],\n",
      "       [  5.38746301e-02,   1.77415570e-03,   5.13351761e-02, ...,\n",
      "          6.46208539e-02,   4.25783820e-02,   4.49711706e-02],\n",
      "       [  1.45109469e-04,   3.60735279e-02,   1.76577866e-02, ...,\n",
      "          3.12014100e-02,   1.27912477e-03,   1.29975223e-02]]), array([[ 1.3734247 ,  0.93284495,  0.0314954 , ...,  1.2160506 ,\n",
      "         1.01511079,  2.14804353],\n",
      "       [ 0.1036058 ,  0.44325154,  1.14421826, ...,  0.86297749,\n",
      "         1.06878514,  2.02077376],\n",
      "       [ 1.69709532,  0.6541169 ,  1.42901819, ...,  0.21342498,\n",
      "         0.8089407 ,  1.51561216],\n",
      "       ..., \n",
      "       [-0.05142836, -0.06079834,  0.52005159, ...,  1.73093767,\n",
      "         0.85561605,  1.79898377],\n",
      "       [ 1.6338292 ,  1.05027413,  1.76108219, ...,  1.94037567,\n",
      "         0.07359572,  1.94301782],\n",
      "       [ 1.64101083,  1.47376025,  1.50730485, ...,  0.29493474,\n",
      "         1.669824  ,  0.0968842 ]])), (array([[ 0.11205316,  0.12995222,  0.11659358, ...,  0.1238822 ,\n",
      "         0.09054216,  0.13200295],\n",
      "       [ 0.05658883,  0.10736417,  0.11600899, ...,  0.12453314,\n",
      "         0.15597529,  0.06083424],\n",
      "       [ 0.0812041 ,  0.08982119,  0.10050206, ...,  0.09688057,\n",
      "         0.09249132,  0.08524456],\n",
      "       ..., \n",
      "       [ 0.01695349,  0.05981861,  0.00661586, ...,  0.05933466,\n",
      "         0.01108654,  0.00324757],\n",
      "       [ 0.00481731,  0.05485594,  0.04535104, ...,  0.0203078 ,\n",
      "         0.05599876,  0.03314686],\n",
      "       [ 0.05605098,  0.01237449,  0.05429222, ...,  0.02540956,\n",
      "         0.0274798 ,  0.02920806]]), array([[ 1.59573736,  1.12177267,  0.48578138, ...,  1.3188514 ,\n",
      "         2.08837136,  0.12907011],\n",
      "       [ 0.18933366,  2.22238379,  2.25853397, ...,  1.23925557,\n",
      "         0.84824038,  1.01220915],\n",
      "       [ 0.93774249,  1.78771775,  0.44154867, ...,  1.48942863,\n",
      "         1.56134529,  1.11050517],\n",
      "       ..., \n",
      "       [ 2.04064494,  0.76588255,  2.01420148, ...,  0.30124597,\n",
      "         1.80119064,  2.10750679],\n",
      "       [ 1.96714741,  2.08085982,  1.07703317, ...,  1.94376938,\n",
      "         0.9730085 ,  1.99007177],\n",
      "       [ 1.86400378,  0.85737258,  2.22550418, ...,  0.02598044,\n",
      "         1.7524864 ,  1.18736271]])), (array([[ 0.12296226,  0.09862018,  0.09795693, ...,  0.12471727,\n",
      "         0.08178089,  0.10426132],\n",
      "       [ 0.14366458,  0.10633109,  0.1464682 , ...,  0.04906707,\n",
      "         0.13513273,  0.04935501],\n",
      "       [ 0.05441001,  0.08302362,  0.13797477, ...,  0.03952187,\n",
      "         0.06505043,  0.11981613],\n",
      "       ..., \n",
      "       [ 0.05121303,  0.05160563,  0.05801062, ...,  0.06128621,\n",
      "         0.026231  ,  0.0267185 ],\n",
      "       [ 0.04816549,  0.0392921 ,  0.03151741, ...,  0.04448854,\n",
      "         0.0086383 ,  0.00500123],\n",
      "       [ 0.06802901,  0.06218789,  0.03356755, ...,  0.00578832,\n",
      "         0.04992226,  0.05327286]]), array([[ 1.70304253,  1.78485874,  1.49119453, ...,  0.2573287 ,\n",
      "         1.12721402,  0.80865969],\n",
      "       [ 2.23590145,  1.1856616 ,  1.86356005, ...,  2.24980093,\n",
      "         0.177242  ,  0.21523351],\n",
      "       [ 1.65537432,  1.97016186,  1.08279363, ...,  1.13269222,\n",
      "         0.49110951,  1.14626931],\n",
      "       ..., \n",
      "       [ 1.3854096 ,  1.16218177,  1.27831553, ...,  1.44053616,\n",
      "         1.98083745,  1.80408338],\n",
      "       [ 0.89688029,  1.60689952,  2.21516642, ...,  1.3870074 ,\n",
      "         0.10361075,  0.88175338],\n",
      "       [ 1.69836184,  0.04959824,  2.05846343, ...,  1.81570399,\n",
      "         1.38717063,  0.38387715]])), (array([[ 0.08692817,  0.12760621,  0.05423438, ...,  0.17227951,\n",
      "         0.06836751,  0.14782297],\n",
      "       [ 0.05169175,  0.10309492,  0.06896123, ...,  0.12007175,\n",
      "         0.16088556,  0.14023306],\n",
      "       [ 0.06193817,  0.16384835,  0.0444382 , ...,  0.08317151,\n",
      "         0.07784258,  0.1094259 ],\n",
      "       ..., \n",
      "       [ 0.07166903,  0.04784806,  0.04143395, ...,  0.00154099,\n",
      "         0.02031534,  0.03789917],\n",
      "       [ 0.0226112 ,  0.0533104 ,  0.04991794, ...,  0.06217333,\n",
      "         0.05136283,  0.0108517 ],\n",
      "       [ 0.01991223,  0.03255866,  0.05449902, ...,  0.06298935,\n",
      "         0.07285473,  0.06660518]]), array([[ 0.65027316,  1.34121994,  2.0915683 , ...,  1.41873796,\n",
      "         1.43972839,  0.32684043],\n",
      "       [ 0.43333093,  1.81154847,  0.23009817, ...,  1.1553868 ,\n",
      "         1.16498657,  0.17055535],\n",
      "       [ 0.68541208,  1.55431987,  0.75932279, ...,  1.26716753,\n",
      "         1.10877878,  0.48773838],\n",
      "       ..., \n",
      "       [ 1.35847425,  0.84169204,  0.09887752, ...,  1.9807433 ,\n",
      "        -0.04998355,  0.72329894],\n",
      "       [ 1.21087335, -0.02528132,  1.94048886, ...,  0.83807939,\n",
      "         1.54151808,  1.34379094],\n",
      "       [ 1.8200069 ,  0.71494044,  0.33931819, ...,  1.34909749,\n",
      "         2.10183477,  1.78261317]])), (array([[ 0.06877752,  0.06865491,  0.13552772, ...,  0.13069413,\n",
      "         0.13288826,  0.12799103],\n",
      "       [ 0.05535047,  0.05543904,  0.0829934 , ...,  0.12490361,\n",
      "         0.17540349,  0.22131316],\n",
      "       [ 0.11720468,  0.05381842,  0.15957293, ...,  0.14813832,\n",
      "         0.11666498,  0.07275365],\n",
      "       ..., \n",
      "       [ 0.02270805,  0.06327086,  0.06529102, ...,  0.03391169,\n",
      "         0.04671733,  0.07361944],\n",
      "       [ 0.01679517,  0.03794693,  0.03761005, ...,  0.01086069,\n",
      "         0.03738958,  0.04393206],\n",
      "       [ 0.03905306,  0.00249388,  0.0003417 , ...,  0.0134394 ,\n",
      "         0.02014148,  0.06862624]]), array([[ 1.7355659 ,  0.83590555,  0.9868364 , ...,  1.76511803,\n",
      "         2.15780268,  1.1481832 ],\n",
      "       [ 1.42864656,  0.36009875,  1.98773648, ...,  0.0150857 ,\n",
      "         1.02477167,  0.5130966 ],\n",
      "       [ 1.12553107,  1.29982684,  1.38869394, ...,  0.20674268,\n",
      "         1.9186806 ,  1.25493551],\n",
      "       ..., \n",
      "       [ 1.92629324,  0.53029415,  0.04535986, ...,  0.42329742,\n",
      "         0.25774296,  1.67400162],\n",
      "       [ 1.66146806,  1.94199969,  0.52093938, ...,  0.71169389,\n",
      "         1.89144094,  0.41285004],\n",
      "       [ 2.21417419,  0.0711751 ,  0.79282701, ...,  2.16820921,\n",
      "         0.8181117 ,  2.23389416]]))]\n",
      "1.02207824693\n",
      "1.02286028394\n",
      "1.02266313406\n",
      "1.02100045275\n",
      "1.0216440304\n",
      "1.02100045275\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEdCAYAAAD5KpvoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njDHGBPX/ARAHK+1aoOtMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2700a853be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matrix_factorization import multiple_matrix_factorization_SGD\n",
    "from helpers import pick_lowest_rmse\n",
    "# set seed\n",
    "np.random.seed(988)\n",
    "results = multiple_matrix_factorization_SGD(train, test, num_epochs=500, ntries=5)\n",
    "print(results)\n",
    "rmse, user_features, item_features = pick_lowest_rmse(test, results, test.nonzero())\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 1000, number of users: 10000\n"
     ]
    }
   ],
   "source": [
    "from helpers import exportSubmission\n",
    "pred =  (item_features @ user_features.T)\n",
    "exportSubmission(\"data/submission_MF.csv\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matrix_factorization import matrix_factorization_SGD\n",
    "from helpers import compute_error\n",
    "errors = []\n",
    "for i in np.arange(5, 40, 5):\n",
    "    user_features, item_features = matrix_factorization_SGD(train, test, num_epochs = 1000, num_features = i)\n",
    "    error = compute_error(test, user_features, item_features, test.nonzero())\n",
    "    errors.append(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plots import visualization\n",
    "visualization(np.arange(5, 40, 5),errors,errors)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # update and return user feature.\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # update and return item feature.\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import build_index_groups\n",
    "\n",
    "\n",
    "def ALS(train, test):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # start you ALS-WR algorithm.\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "\n",
    "ALS(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Computing prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.ones(valid_ratings.shape)\n",
    "for col in range(valid_ratings.shape[0]):\n",
    "    pred[col,:] *= ratings_means_list[col]\n",
    "    \n",
    "exportSubmission(\"data/final_submission.csv\", pred)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
