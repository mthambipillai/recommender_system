{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Note that `ratings` is a sparse matrix that in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 1000, number of users: 10000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"data/data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEbCAYAAABgLnslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvJNyzjmXW95JOeecyy3vpJxzzuXW/wMEU0eiEQdsPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f34773bac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 3, min # of users per item = 8.\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nonzero elements in original data:1176952\n",
      "Total number of nonzero elements in train data:1058987\n",
      "Total number of nonzero elements in test data:117965\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_train_test_data\n",
    "from helpers import split_data\n",
    "\n",
    "valid_ratings, train_unfiltered, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=0, p_test=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from outliers_filtering import *\n",
    "#d = disagreements(train_unfiltered)\n",
    "#plot_disagreements(d)\n",
    "#train = filter_outliers(train_unfiltered,d)\n",
    "#nfiltered = train_unfiltered.nnz - train.nnz\n",
    "#print(\"number of filtered ratings : {}\".format(nfiltered))\n",
    "train = train_unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from outliers_filtering import threshold_tests\n",
    "#threshold_tests(d, train_unfiltered, valid_ratings, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the global mean to do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helpers import calculate_mse\n",
    "from baselines import baseline_global_mean, compute_rmse\n",
    "\n",
    "train_mean, test_mean = baseline_global_mean(train, test)\n",
    "pred = np.ones(train.shape) * train_mean\n",
    "test_pred = np.ones(test.shape) * test_mean\n",
    "\n",
    "\n",
    "rmse_test = compute_rmse(test, test_pred)\n",
    "rmse_submission = compute_rmse(valid_ratings, pred)\n",
    "print(rmse_test)\n",
    "print(rmse_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the user means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from baselines import baseline_user_mean\n",
    "\n",
    "train_means, test_means = baseline_user_mean(train, test)\n",
    "train_means_list = train_means.tolist()\n",
    "pred = np.ones(train.shape)\n",
    "for col in range(train.shape[1]):\n",
    "    pred[:,col] *= train_means_list[0][col]\n",
    "test_means_list = test_means.tolist()\n",
    "test_pred = np.ones(test.shape)\n",
    "for col in range(test.shape[1]):\n",
    "    test_pred[:,col] *= test_means_list[0][col]\n",
    "\n",
    "rmse_test = compute_rmse(test, test_pred)\n",
    "rmse_submission = compute_rmse(valid_ratings, pred)\n",
    "print(rmse_test)\n",
    "print(rmse_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the item means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from baselines import baseline_item_mean\n",
    "from helpers import exportSubmission\n",
    "\n",
    "train_means, test_means = baseline_item_mean(train, test)\n",
    "train_means_list = train_means.tolist()\n",
    "pred = np.ones(train.shape)\n",
    "for col in range(train.shape[0]):\n",
    "    pred[col,:] *= train_means_list[col]\n",
    "test_means_list = test_means.tolist()\n",
    "test_pred = np.ones(test.shape)\n",
    "for col in range(test.shape[0]):\n",
    "    test_pred[col,:] *= test_means_list[col]\n",
    "\n",
    "rmse_test = compute_rmse(test, test_pred)\n",
    "rmse_submission = compute_rmse(valid_ratings, pred)\n",
    "print(rmse_test)\n",
    "print(rmse_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost by the method of matrix factorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: k = 30, RMSE on training set: 1.2826366743059094.\n",
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 2.0818817363770665.\n",
      "iter: 0, RMSE on test set: 2.05332580310938.\n",
      "iter: 10, RMSE on training set: 1.1251553858281957.\n",
      "iter: 10, RMSE on test set: 1.0943798952219048.\n",
      "iter: 20, RMSE on training set: 1.0554216877085905.\n",
      "iter: 20, RMSE on test set: 1.0250965470217406.\n",
      "iter: 30, RMSE on training set: 1.0339823298639654.\n",
      "iter: 30, RMSE on test set: 1.004488120680532.\n",
      "iter: 40, RMSE on training set: 1.0235905548177717.\n",
      "iter: 40, RMSE on test set: 0.9948556567251996.\n",
      "iter: 50, RMSE on training set: 1.0176385848454204.\n",
      "iter: 50, RMSE on test set: 0.9894089039808389.\n",
      "iter: 60, RMSE on training set: 1.0136608016782331.\n",
      "iter: 60, RMSE on test set: 0.985965662618629.\n",
      "iter: 70, RMSE on training set: 1.0105940222751648.\n",
      "iter: 70, RMSE on test set: 0.9834988039647943.\n",
      "iter: 80, RMSE on training set: 1.0082909805137577.\n",
      "iter: 80, RMSE on test set: 0.9818013266345172.\n",
      "iter: 90, RMSE on training set: 1.0064065924016585.\n",
      "iter: 90, RMSE on test set: 0.9803366284502495.\n",
      "iter: 100, RMSE on training set: 1.004834884480192.\n",
      "iter: 100, RMSE on test set: 0.9791544219401567.\n",
      "iter: 110, RMSE on training set: 1.0034545043993734.\n",
      "iter: 110, RMSE on test set: 0.9781620021224696.\n",
      "iter: 120, RMSE on training set: 1.0023209661304218.\n",
      "iter: 120, RMSE on test set: 0.9773791214781435.\n",
      "iter: 130, RMSE on training set: 1.0012159373467635.\n",
      "iter: 130, RMSE on test set: 0.976836152659388.\n",
      "iter: 140, RMSE on training set: 1.0002755477849088.\n",
      "iter: 140, RMSE on test set: 0.9762311680347721.\n",
      "iter: 150, RMSE on training set: 0.9994368841522642.\n",
      "iter: 150, RMSE on test set: 0.9758091493489703.\n",
      "iter: 160, RMSE on training set: 0.9986603582273883.\n",
      "iter: 160, RMSE on test set: 0.9753247145089744.\n",
      "iter: 170, RMSE on training set: 0.9979853295503044.\n",
      "iter: 170, RMSE on test set: 0.9750234682687889.\n",
      "iter: 180, RMSE on training set: 0.9972771490005677.\n",
      "iter: 180, RMSE on test set: 0.9745846474842906.\n",
      "iter: 190, RMSE on training set: 0.9966765989733287.\n",
      "iter: 190, RMSE on test set: 0.9743136268832386.\n",
      "iter: 200, RMSE on training set: 0.9960815472636959.\n",
      "iter: 200, RMSE on test set: 0.9739501227860445.\n",
      "iter: 210, RMSE on training set: 0.9955482400767585.\n",
      "iter: 210, RMSE on test set: 0.973748920931923.\n",
      "iter: 220, RMSE on training set: 0.995034010643079.\n",
      "iter: 220, RMSE on test set: 0.9735722351444591.\n",
      "iter: 230, RMSE on training set: 0.9944856073033072.\n",
      "iter: 230, RMSE on test set: 0.9732940731751641.\n",
      "iter: 240, RMSE on training set: 0.9940705602397626.\n",
      "iter: 240, RMSE on test set: 0.9731547200420958.\n",
      "iter: 250, RMSE on training set: 0.9936757357191831.\n",
      "iter: 250, RMSE on test set: 0.9730460475700676.\n",
      "iter: 260, RMSE on training set: 0.993244242194957.\n",
      "iter: 260, RMSE on test set: 0.972847136999783.\n",
      "iter: 270, RMSE on training set: 0.9928341794924197.\n",
      "iter: 270, RMSE on test set: 0.9727248480056909.\n",
      "iter: 280, RMSE on training set: 0.9923764277332354.\n",
      "iter: 280, RMSE on test set: 0.9724904949593561.\n",
      "iter: 290, RMSE on training set: 0.9920231340722183.\n",
      "iter: 290, RMSE on test set: 0.972459691871413.\n",
      "iter: 300, RMSE on training set: 0.9917268096403038.\n",
      "iter: 300, RMSE on test set: 0.9723071865795573.\n",
      "iter: 310, RMSE on training set: 0.9913765845425366.\n",
      "iter: 310, RMSE on test set: 0.9722420724681602.\n",
      "iter: 320, RMSE on training set: 0.9910366429834755.\n",
      "iter: 320, RMSE on test set: 0.9720626784062505.\n",
      "iter: 330, RMSE on training set: 0.990739875658452.\n",
      "iter: 330, RMSE on test set: 0.9720607894611194.\n",
      "iter: 340, RMSE on training set: 0.9904181468626697.\n",
      "iter: 340, RMSE on test set: 0.9719063842681495.\n",
      "iter: 350, RMSE on training set: 0.9901200931385205.\n",
      "iter: 350, RMSE on test set: 0.9718669219255174.\n",
      "iter: 360, RMSE on training set: 0.9897930613291455.\n",
      "iter: 360, RMSE on test set: 0.9718280478531038.\n",
      "iter: 370, RMSE on training set: 0.9895282456502773.\n",
      "iter: 370, RMSE on test set: 0.97174859761572.\n",
      "iter: 380, RMSE on training set: 0.989309313932299.\n",
      "iter: 380, RMSE on test set: 0.9716924495269031.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-962963aa390a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# set seed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m988\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiple_matrix_factorization_SGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpick_lowest_rmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Melkior\\Documents\\EPFL\\Master semester 1\\Pattern Classification and Machine Learning\\project 2\\recommender_system\\Notebook\\matrix_factorization.py\u001b[0m in \u001b[0;36mmultiple_matrix_factorization_SGD\u001b[1;34m(train, test, num_epochs, num_features, ntries)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0muser_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix_factorization_SGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Melkior\\Documents\\EPFL\\Master semester 1\\Pattern Classification and Machine Learning\\project 2\\recommender_system\\Notebook\\matrix_factorization.py\u001b[0m in \u001b[0;36mmatrix_factorization_SGD\u001b[1;34m(train, test, num_epochs, num_features)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnz_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnz_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mpred_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m             \u001b[1;31m#compute gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mitem_grad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpred_error\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0muser_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Melkior\\Anaconda3\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from matrix_factorization import multiple_matrix_factorization_SGD\n",
    "from helpers import pick_lowest_rmse\n",
    "# set seed\n",
    "np.random.seed(988)\n",
    "results = multiple_matrix_factorization_SGD(train, test, num_epochs=500, ntries=5)\n",
    "rmse, user_features, item_features = pick_lowest_rmse(test, results, test.nonzero())\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import exportSubmission\n",
    "pred =  (item_features @ user_features.T)\n",
    "exportSubmission(\"data/submission_MF.csv\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matrix_factorization import matrix_factorization_SGD\n",
    "from helpers import compute_error\n",
    "user_features_list = []\n",
    "item_features_list = []\n",
    "errors = []\n",
    "for i in np.arange(1, 10, 1):\n",
    "    user_features, item_features = matrix_factorization_SGD(train, test, num_epochs = 1000, num_features = i)\n",
    "    user_features_list.append(user_features)\n",
    "    item_features_list.append(item_features)\n",
    "    error = compute_error(test, user_features, item_features, test.nonzero())\n",
    "    errors.append(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plots import visualization\n",
    "visualization(np.arange(5, 40, 5),errors,errors)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plots import visualization\n",
    "visualization(np.arange(1, 10, 1),errors,errors)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_features = user_features_list[2]\n",
    "item_features = item_features_list[2]\n",
    "compute_error(test, user_features, item_features, test.nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix_factorization_SGD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-02079c342cc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muser_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix_factorization_SGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_ratings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'matrix_factorization_SGD' is not defined"
     ]
    }
   ],
   "source": [
    "from matrix_factorization import matrix_factorization_SGD\n",
    "user_features, item_features = matrix_factorization_SGD(valid_ratings, test, num_epochs = 300, num_features = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(\"data/features/best2_user_features.npy\", user_features)\n",
    "np.save(\"data/features/best2_item_features.npy\", item_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # update and return user feature.\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # update and return item feature.\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import build_index_groups\n",
    "\n",
    "\n",
    "def ALS(train, test):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # start you ALS-WR algorithm.\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "\n",
    "ALS(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Computing prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.ones(valid_ratings.shape)\n",
    "for col in range(valid_ratings.shape[0]):\n",
    "    pred[col,:] *= ratings_means_list[col]\n",
    "    \n",
    "exportSubmission(\"data/final_submission.csv\", pred)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
